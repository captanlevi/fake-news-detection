{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tYYDPAn97xIu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import gensim\n",
    "import re\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "from torch.nn.functional import mse_loss \n",
    "import pickle\n",
    "word_limit = 8\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hc107DsuMQhI"
   },
   "outputs": [],
   "source": [
    "train_path = \"drive/My Drive/News/LIAR-PLUS-master/dataset/train2.tsv\"\n",
    "test_path = \"drive/My Drive/News/LIAR-PLUS-master/dataset/test2.tsv\"\n",
    "valid_path = \"drive/My Drive/News/LIAR-PLUS-master/dataset/val2.tsv\"\n",
    "google_path = \"drive/My Drive/News/GoogleNews-vectors-negative300.bin\"\n",
    "save_path = \"drive/My Drive/News\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "0U7KGyrkMd4W",
    "outputId": "d6ddef85-f0a0-4b6d-d77e-24f05adfc7e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format(google_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JdFxWRgKJfnG"
   },
   "outputs": [],
   "source": [
    "def clean_sentence(s):\n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "    new_sent = []\n",
    "    for w in s.split(\" \"):\n",
    "        w = regex.sub('', w)\n",
    "        if(w == \"didnt\"):\n",
    "            new_sent.append(\"did\")\n",
    "            new_sent.append(\"not\")\n",
    "        elif(w == \"isnt\"):\n",
    "            new_sent.append(\"is\")\n",
    "            new_sent.append(\"not\")\n",
    "        elif(w == \"wasnt\"):\n",
    "            new_sent.append(\"was\")\n",
    "            new_sent.append(\"not\")\n",
    "        elif(w == \"doesnt\"):\n",
    "            new_sent.append(\"does\")\n",
    "            new_sent.append(\"not\")\n",
    "        elif(w == \"hasnt\"):\n",
    "            new_sent.append(\"has\")\n",
    "            new_sent.append(\"not\")\n",
    "        elif(w == \"bushs\"):\n",
    "            new_sent.append(\"bush\")  \n",
    "        else:    \n",
    "            new_sent.append(w)\n",
    "    s = \" \".join(new_sent)\n",
    "    return s.strip().lower()\n",
    "\n",
    "def clean_subject(s):\n",
    "    new_sub = []\n",
    "    for w in s.split(\",\"):\n",
    "        sub = w.split(\"-\")[0].lower()\n",
    "        if(sub in word2vec):\n",
    "            new_sub.append(sub)\n",
    "    if(len(new_sub) == 0):\n",
    "        return \"<pad>\"\n",
    "    else:\n",
    "        return \" \".join(new_sub)\n",
    "        \n",
    "def clean_party(s):\n",
    "    new_party = []\n",
    "    for p in s.split(\"-\"):\n",
    "        p = p.lower()\n",
    "        if(p in word2vec):\n",
    "            new_party.append(p)\n",
    "    if(len(new_party) == 0):\n",
    "        return \"<pad>\"\n",
    "    else:\n",
    "        return \" \".join(new_party)\n",
    "\n",
    "\n",
    "def clean_df(df):\n",
    "    df = df[df[15].map(lambda x: isinstance(x, str))]\n",
    "    df = df[df[3].map(lambda x: isinstance(x, str))]\n",
    "    df = df[df[4].map(lambda x: isinstance(x, str))]\n",
    "    df[15] = df[15].map(lambda x : clean_sentence(x))\n",
    "    df[3] = df[3].map(lambda x : clean_sentence(x))\n",
    "    df[4] = df[4].map(lambda x : clean_subject(x))\n",
    "    df[8] = df[8].map(lambda x : clean_party(x))\n",
    "    cred = df[[9,10 ,11, 12,13]]\n",
    "    df[\"cred\"] = cred.values.tolist()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K0FR8oh5CG48"
   },
   "outputs": [],
   "source": [
    "def get_data(tp):\n",
    "    if(tp == \"train\"):\n",
    "        path = train_path\n",
    "    elif(tp == \"valid\"):\n",
    "        path = valid_path\n",
    "    elif(tp == \"test\"):\n",
    "        path = test_path\n",
    "       \n",
    "    df  = pd.read_csv(path , sep = \"\\t\" ,  header  = None)\n",
    "    print(\"Orignal len \" ,len(df))\n",
    "    df = clean_df(df)\n",
    "    print(\"len after cleaning \" , len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "lg0gDvavI4BF",
    "outputId": "629dff9c-3025-43ae-9f17-398c2220ff23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orignal len  10240\n",
      "len after cleaning  10154\n",
      "Orignal len  1267\n",
      "len after cleaning  1258\n",
      "Orignal len  1284\n",
      "len after cleaning  1280\n"
     ]
    }
   ],
   "source": [
    "train_data = get_data(\"train\")\n",
    "test_data = get_data(\"test\")\n",
    "valid_data = get_data(\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ki7E9KoJRwd"
   },
   "outputs": [],
   "source": [
    "sents = train_data[3].tolist() + valid_data[3].values.tolist() + test_data[3].values.tolist() + train_data[15].tolist() + valid_data[15].values.tolist() + test_data[15].values.tolist() + train_data[4].tolist() + valid_data[4].values.tolist() + test_data[4].values.tolist() + train_data[8].tolist() + valid_data[8].values.tolist() + test_data[8].values.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZrhwJLk0QK-F"
   },
   "outputs": [],
   "source": [
    "def build_dict(sents , word2vec):\n",
    "    word2count = {}\n",
    "    for s in sents:\n",
    "        for w in s.split(\" \"):\n",
    "            if(w not in word2count):\n",
    "                word2count[w] = 1\n",
    "            else:\n",
    "                word2count[w] = word2count[w] + 1            \n",
    "    word2index = {}\n",
    "    index2word = {}\n",
    "    word2index[\"<pad>\"] = 0\n",
    "    word2index[\"<bos>\"] = 1\n",
    "    word2index[\"<eos>\"] = 2\n",
    "    word2index[\"<unk>\"] = 3\n",
    "    index2word[0] = \"<pad>\"\n",
    "    index2word[1] = \"<bos>\"\n",
    "    index2word[2] = \"<eos>\"\n",
    "    index2word[3] = \"<unk>\"\n",
    "    index = 4\n",
    "    embedding = []\n",
    "    for i in range(index):\n",
    "        embedding.append(np.random.normal(size = 300))\n",
    "    count = 0\n",
    "    for w in word2count:\n",
    "        if(w in word2vec):\n",
    "            word2index[w] = index\n",
    "            index2word[index] = w\n",
    "            embedding.append(word2vec[w]) \n",
    "            index = index + 1\n",
    "        elif(word2count[w] > word_limit):\n",
    "            count = count + 1\n",
    "            word2index[w] = index\n",
    "            index2word[index] = w\n",
    "            embedding.append(np.random.normal(size = 300))\n",
    "            index = index + 1\n",
    "    print(count , \"new words randomly init\")\n",
    "    return word2index , index2word , np.array(embedding)\n",
    "        \n",
    "                \n",
    "            \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "b_WjjmCHRy1l",
    "outputId": "ec4367f3-6880-4d52-823d-aabb4048095f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418 new words randomly init\n"
     ]
    }
   ],
   "source": [
    "word2index , index2word  ,embedding = build_dict(sents , word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ldKaUqsMi1dm"
   },
   "outputs": [],
   "source": [
    "def save_dict(path , dct):\n",
    "    with open(path , \"wb\") as handle:\n",
    "        pickle.dump(dct , handle , protocol = pickle.HIGHEST_PROTOCOL)\n",
    "def load_dict(path):\n",
    "    with open(path, \"rb\") as handle:\n",
    "        b = pickle.load(handle)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W89PL_LUgh31"
   },
   "outputs": [],
   "source": [
    "save_dict(os.path.join(save_path , \"word2index.pkl\") , word2index)\n",
    "save_dict(os.path.join(save_path , \"index2word.pkl\") , index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TdUtJnosltGM"
   },
   "outputs": [],
   "source": [
    "np.save(os.path.join(save_path , \"embedding.npy\") , embedding)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "preprocess",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
