{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qx-5y6q1_Kcg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import random\n",
    "import matplotlib.pyplot as plt \n",
    "import re\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "save_path = \"drive/My Drive/News\"\n",
    "word2index_path = \"drive/My Drive/News/word2index.pkl\"\n",
    "index2word_path = \"drive/My Drive/News/index2word.pkl\"\n",
    "embedding_path = \"drive/My Drive/News/embedding.npy\"\n",
    "train_path = \"drive/My Drive/News/LIAR-PLUS-master/dataset/train2.tsv\"\n",
    "test_path = \"drive/My Drive/News/LIAR-PLUS-master/dataset/test2.tsv\"\n",
    "valid_path = \"drive/My Drive/News/LIAR-PLUS-master/dataset/val2.tsv\"\n",
    "model_save_path = \"drive/My Drive/News/six_way_model\"\n",
    "max_claim = 51\n",
    "min_claim = 2\n",
    "max_just = 261\n",
    "min_claim = 4\n",
    "batch_size = 50\n",
    "lr = .0001\n",
    "rep = 10154//batch_size\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LQYN-w_dGmNP"
   },
   "outputs": [],
   "source": [
    "def save_dict(path , dct):\n",
    "    with open(path , \"wb\") as handle:\n",
    "        pickle.dump(dct , handle , protocol = pickle.HIGHEST_PROTOCOL)\n",
    "def load_dict(path):\n",
    "    with open(path, \"rb\") as handle:\n",
    "        b = pickle.load(handle)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mE2X46muVZUE"
   },
   "outputs": [],
   "source": [
    "embedding = np.load(embedding_path).astype(np.float32)\n",
    "word2index = load_dict(word2index_path)\n",
    "index2word = load_dict(index2word_path)\n",
    "embedding = torch.tensor(embedding).to(device).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xb7vjzx8_-W0"
   },
   "outputs": [],
   "source": [
    "def clean_sentence(s):\n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "    new_sent = []\n",
    "    for w in s.split(\" \"):\n",
    "        w = regex.sub('', w)\n",
    "        if(w == \"didnt\"):\n",
    "            new_sent.append(\"did\")\n",
    "            new_sent.append(\"not\")\n",
    "        elif(w == \"isnt\"):\n",
    "            new_sent.append(\"is\")\n",
    "            new_sent.append(\"not\")\n",
    "        elif(w == \"wasnt\"):\n",
    "            new_sent.append(\"was\")\n",
    "            new_sent.append(\"not\")\n",
    "        elif(w == \"doesnt\"):\n",
    "            new_sent.append(\"does\")\n",
    "            new_sent.append(\"not\")\n",
    "        elif(w == \"hasnt\"):\n",
    "            new_sent.append(\"has\")\n",
    "            new_sent.append(\"not\")\n",
    "        elif(w == \"bushs\"):\n",
    "            new_sent.append(\"bush\")  \n",
    "        else:    \n",
    "            new_sent.append(w)\n",
    "    s = \" \".join(new_sent)\n",
    "    return s.strip().lower()\n",
    "\n",
    "def clean_subject(s):\n",
    "    new_sub = []\n",
    "    for w in s.split(\",\"):\n",
    "        sub = w.split(\"-\")[0].lower()\n",
    "        if(sub in word2index):\n",
    "            new_sub.append(sub)\n",
    "    if(len(new_sub) == 0):\n",
    "        return \"<pad>\"\n",
    "    else:\n",
    "        return \" \".join(new_sub)\n",
    "        \n",
    "def clean_party(s):\n",
    "    new_party = []\n",
    "    for p in s.split(\"-\"):\n",
    "        p = p.lower()\n",
    "        if(p in word2index):\n",
    "            new_party.append(p)\n",
    "    if(len(new_party) == 0):\n",
    "        return \"<pad>\"\n",
    "    else:\n",
    "        return \" \".join(new_party)\n",
    "\n",
    "\n",
    "def clean_df(df):\n",
    "    df = df[df[15].map(lambda x: isinstance(x, str))]\n",
    "    df = df[df[3].map(lambda x: isinstance(x, str))]\n",
    "    df = df[df[4].map(lambda x: isinstance(x, str))]\n",
    "    df[15] = df[15].map(lambda x : clean_sentence(x))\n",
    "    df[3] = df[3].map(lambda x : clean_sentence(x))\n",
    "    df[4] = df[4].map(lambda x : clean_subject(x))\n",
    "    df[8] = df[8].map(lambda x : clean_party(x))\n",
    "    df[8] = df[8].map(lambda x : clean_subject(x))\n",
    "    cred = df[[9,10 ,11, 12,13]]\n",
    "    df[\"cred\"] = cred.values.tolist()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P1GPZ5cYASr-"
   },
   "outputs": [],
   "source": [
    "def get_data(tp):\n",
    "    if(tp == \"train\"):\n",
    "        path = train_path\n",
    "    elif(tp == \"valid\"):\n",
    "        path = valid_path\n",
    "    elif(tp == \"test\"):\n",
    "        path = test_path\n",
    "       \n",
    "    df  = pd.read_csv(path , sep = \"\\t\" ,  header  = None)\n",
    "    print(\"Orignal training points \" ,len(df))\n",
    "    df = clean_df(df)\n",
    "    print(\"cleaned training points \" , len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "xYNWa7znVuLh",
    "outputId": "1270142d-29f0-4d9d-ce30-d045d4136ec7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orignal training points  10240\n",
      "cleaned training points  10154\n",
      "Orignal training points  1284\n",
      "cleaned training points  1280\n",
      "Orignal training points  1267\n",
      "cleaned training points  1258\n"
     ]
    }
   ],
   "source": [
    "train_data = get_data(\"train\")\n",
    "train_data = train_data[[3,4,8,\"cred\" , 15 , 2]]\n",
    "train_data.columns = [\"claim\" , \"subjects\" ,\"party\", \"cred\" , \"just\" , \"label\"]\n",
    "\n",
    "valid_data = get_data(\"valid\")\n",
    "valid_data = valid_data[[3,4,8,\"cred\" , 15 , 2]]\n",
    "valid_data.columns = [\"claim\" , \"subjects\" ,\"party\", \"cred\" , \"just\" , \"label\"]\n",
    "\n",
    "test_data = get_data(\"test\")\n",
    "test_data = test_data[[3,4,8,\"cred\" , 15 , 2]]\n",
    "test_data.columns = [\"claim\" , \"subjects\" ,\"party\", \"cred\" , \"just\" , \"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQ4hyNCjRqRk"
   },
   "outputs": [],
   "source": [
    "labels = list(train_data[\"label\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YeZcS7t-Rwzh"
   },
   "outputs": [],
   "source": [
    "label_dict = {'pants-fire':0 , 'false' :1 ,'barely-true':2 , 'half-true':3 , 'mostly-true':4 , 'true':5 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uOTLkyqbAVH2"
   },
   "outputs": [],
   "source": [
    "def cut_sentence(s , tp):\n",
    "    new_s = [word2index[\"<bos>\"]]\n",
    "    for w in s.split(\" \"):\n",
    "        if(w in word2index):\n",
    "            new_s.append(word2index[w])\n",
    "    if(tp == \"claim\"):\n",
    "        mx = max_claim\n",
    "    elif(tp == \"just\"):\n",
    "        mx = max_just\n",
    "    if(len(new_s) > mx):\n",
    "        new_s = new_s[: mx]    \n",
    "    new_s.append(word2index[\"<eos>\"])    \n",
    "    return new_s\n",
    "\n",
    "def process_cred(arr):\n",
    "    s = sum(arr)\n",
    "    if(s ==0 ):\n",
    "        return arr\n",
    "    else:\n",
    "        return [x/s for x in arr]\n",
    "\n",
    "def process_data(df):\n",
    "    df[\"claim\"] = df[\"claim\"].map(lambda x : cut_sentence(x , \"claim\"))\n",
    "    df[\"just\"] = df[\"just\"].map(lambda x : cut_sentence(x , \"just\"))\n",
    "    df[\"label\"] = df[\"label\"].map(lambda x : label_dict[x])\n",
    "    df[\"cred\"] = df[\"cred\"].map(lambda x : process_cred(x))\n",
    "    df[\"party\"] = df[\"party\"].map(lambda x : word2index[x])\n",
    "    return df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5XibvwFbAev0"
   },
   "outputs": [],
   "source": [
    "train_df = process_data(train_data)\n",
    "valid_df = process_data(valid_data)\n",
    "test_df  = process_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "urYOjkkFa4bg"
   },
   "outputs": [],
   "source": [
    "just = train_df[\"just\"].values.tolist()\n",
    "claim = train_df[\"claim\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pi_tVj7eOZsx"
   },
   "outputs": [],
   "source": [
    "def get_batch(df , batch_size):\n",
    "    batch = df.sample(batch_size)\n",
    "    claim = batch[\"claim\"].values.tolist()\n",
    "    just = batch[\"just\"].values.tolist()\n",
    "    party = torch.tensor(batch[\"party\"].values.tolist())\n",
    "    claim = list(map(lambda x : torch.tensor(x) , claim)) \n",
    "    claim = pad_sequence(claim , batch_first = True)\n",
    "    if(claim.size(1) < 20):\n",
    "        pad = torch.zeros(claim.size(0) , 20 - claim.size(1)).long()\n",
    "        claim = torch.cat((claim , pad) , dim = 1)\n",
    "    just = list(map(lambda x : torch.tensor(x) , just)) \n",
    "    just = pad_sequence(just , batch_first = True)\n",
    "    label = torch.tensor(batch[\"label\"].values)\n",
    "    cred  = torch.tensor(batch[\"cred\"].values.tolist())\n",
    "    return claim.to(device) , just.to(device) , label.to(device) , cred.to(device).double() , party.to(device)\n",
    "    \n",
    "\n",
    "def get_test(df):\n",
    "    batch = df\n",
    "    claim = batch[\"claim\"].values.tolist()\n",
    "    just = batch[\"just\"].values.tolist()\n",
    "    party = torch.tensor(batch[\"party\"].values.tolist())\n",
    "    claim = list(map(lambda x : torch.tensor(x) , claim)) \n",
    "    claim = pad_sequence(claim , batch_first = True)\n",
    "    if(claim.size(1) < 20):\n",
    "        pad = torch.zeros(claim.size(0) , 20 - claim.size(1)).long()\n",
    "        claim = torch.cat((claim , pad) , dim = 1)\n",
    "    just = list(map(lambda x : torch.tensor(x) , just)) \n",
    "    just = pad_sequence(just , batch_first = True)\n",
    "    label = torch.tensor(batch[\"label\"].values)\n",
    "    cred  = torch.tensor(batch[\"cred\"].values.tolist())\n",
    "    return claim.to(device) , just.to(device) , label.to(device) , cred.to(device).double() , party.to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gbPWOiKdU5CN"
   },
   "outputs": [],
   "source": [
    "class Detector(nn.Module):\n",
    "    def __init__(self , word2index = word2index , embedding = embedding , embedding_dim = 300 , dim_hidden = 128  , dim_output = 6 , dim_linear1 = 100, dim_linear2 = 30 , dim_cred = 30 , dim_party = 30):\n",
    "        super().__init__()\n",
    "        self.word2index = word2index\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.dim_output = dim_output\n",
    "        self.dim_linear1 = dim_linear1\n",
    "        self.dim_linear2 = dim_linear2\n",
    "        self.dim_cred = dim_cred\n",
    "        self.dim_party = dim_party\n",
    "        self.embedding = nn.Embedding(len(word2index), self.embedding_dim)\n",
    "        self.embedding.weight = nn.Parameter(embedding)\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.cred_vector =  nn.Linear(5 , self.dim_cred)\n",
    "        self.conv1 = nn.Conv2d(1, 128, (8, self.embedding_dim ))\n",
    "        self.conv2 = nn.Conv2d(1, 128, (4,self.embedding_dim ))\n",
    "        self.conv3 = nn.Conv2d(1, 128, (3,self.embedding_dim ))\n",
    "        self.party_vector = nn.Linear(self.embedding_dim , self.dim_party)\n",
    "        self.cnn_vector =  nn.Linear(128*3 , self.dim_hidden)\n",
    "        self.lstm1 = nn.LSTM(self.embedding_dim , self.dim_hidden , batch_first = True , bidirectional = True)\n",
    "        self.lstm2 = nn.LSTM(self.embedding_dim , self.dim_hidden , batch_first = True , bidirectional = True)\n",
    "        \n",
    "        stacked_dim = self.dim_hidden*5 + self.dim_cred + self.dim_party\n",
    "        \n",
    "        self.stacked_vector = nn.Linear(stacked_dim , self.dim_linear1)\n",
    "        self.vector_vector = nn.Linear(self.dim_linear1 , self.dim_linear2)\n",
    "        self.vector_output = nn.Linear(self.dim_linear2 , self.dim_output)\n",
    "        \n",
    "        self.vector_output = nn.Linear(self.dim_linear2 , self.dim_output)\n",
    "    def forward(self ,claim , just , cred , party ):\n",
    "        emb_claim = self.embedding(claim)\n",
    "        emb_just = self.embedding(just)\n",
    "        emb_party = self.embedding(party)\n",
    "        \n",
    "        cnn_in = emb_claim.unsqueeze(1)\n",
    "        cnn1 = self.conv1(cnn_in).squeeze()\n",
    "        cnn1 = cnn1.mean(dim = 2)\n",
    "        \n",
    "        cnn2 = self.conv2(cnn_in).squeeze()\n",
    "        cnn2 = cnn2.mean(dim = 2)\n",
    "        \n",
    "        cnn3 = self.conv3(cnn_in).squeeze()\n",
    "        cnn3 = cnn3.mean(dim = 2)\n",
    "        \n",
    "        cnn_out = torch.cat((cnn1 , cnn2 , cnn3) , dim = 1)\n",
    "        cnn_out = self.cnn_vector(cnn_out)\n",
    "        \n",
    "        cred = self.cred_vector(cred)\n",
    "        party = self.party_vector(emb_party)\n",
    "        claim , _ = self.lstm1(emb_claim)\n",
    "        just, _ = self.lstm2(emb_just)\n",
    "        claim = claim[: ,-1, :]\n",
    "        just = just[: ,-1, :]\n",
    "        stacked = torch.cat((claim ,cnn_out,  cred ,party ,  just ) , dim = 1)\n",
    "        out = self.stacked_vector(stacked)\n",
    "\n",
    "        out = self.vector_vector(out)\n",
    "\n",
    "        out = self.vector_output(out)\n",
    "        return out\n",
    "        \n",
    "       \n",
    "                    \n",
    "                \n",
    "                \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZDgNbfSuVcSv"
   },
   "outputs": [],
   "source": [
    "model = Detector().double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NgWzc9MhnJrk"
   },
   "outputs": [],
   "source": [
    "params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "optimizer = torch.optim.Adam(params, lr)\n",
    "crit_video = torch.nn.CrossEntropyLoss()\n",
    "def loss1(out , targets):\n",
    "    targets = targets.contiguous().view(-1)\n",
    "    return crit_video(out , targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h6iMJxyBH9ah"
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(df , model):\n",
    "    T = get_test(df)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = model(T[0] ,T[1], T[3] , T[4])\n",
    "    _ , val = torch.max(pred , dim = 1)\n",
    "    val = val.to(\"cpu\").numpy()\n",
    "    label = T[2].to(\"cpu\").numpy()\n",
    "    f1 = f1_score(label, val, average=\"macro\")\n",
    "    precision = precision_score(label, val, average=\"macro\")\n",
    "    recall = recall_score(label, val, average=\"macro\")    \n",
    "    accu = accuracy_score(label , val )\n",
    "    return f1 , precision , recall , accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wnIVIex4nXx5"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(model = model ,data = train_df , epochs = 20 , rep = rep , batch_size = batch_size):\n",
    "    f1_arr = []\n",
    "    loss_arr = []\n",
    "    accu_arr = []\n",
    "    best_model = -1 \n",
    "    best_f1 = -1\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"epoch - \" , epoch+1)\n",
    "        total_loss = 0\n",
    "        for _ in range(rep):\n",
    "            b = get_batch(data , batch_size)\n",
    "            pred = model(b[0] , b[1], b[3] , b[4])\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss1(pred , b[2])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss = total_loss + loss.item()\n",
    "     #   print(total_loss/rep)\n",
    "        loss_arr.append(total_loss/rep)\n",
    "        torch.save(model.state_dict(), os.path.join(model_save_path , \"model\" + str(epoch + 1) + \".pt\"))\n",
    "        f1 , pr , r , accu = calculate_accuracy(valid_df , model)\n",
    "        f1_arr.append(f1)\n",
    "        accu_arr.append(accu)\n",
    "        if(f1 > best_f1):\n",
    "            best_model = epoch +1\n",
    "            best_f1 = f1\n",
    "  #      print(\"validation f1 accuracy\" , f1 , accu)\n",
    "    return best_model , loss_arr ,accu_arr , best_f1\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RnCIU1AKnbwR"
   },
   "outputs": [],
   "source": [
    "best_model , loss_arr , accu_arr , best_f1 = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "PXypEeeFJy06",
    "outputId": "8cfde1db-ed64-49b3-d1dc-22b83f278133"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training\n",
      "Retriving best model.....\n",
      "best_model at epoch 8\n"
     ]
    }
   ],
   "source": [
    "print(\"finished training\")\n",
    "print(\"Retriving best model.....\")\n",
    "print(\"best_model at epoch\" ,best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Qny7caQIu3l"
   },
   "outputs": [],
   "source": [
    "final_model =  Detector().to(device).double()\n",
    "final_model.load_state_dict(torch.load(os.path.join(model_save_path , \"model\" + str(best_model) + \".pt\")  ))\n",
    "test_f1 , test_accu , _ , _ =  calculate_accuracy(test_df , final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "TmZww79JKXYQ",
    "outputId": "3c83e431-cf61-4248-a8ff-c7bc94c3a1d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on test set\n",
      "Accuracy 0.5659734354434024\n",
      "F1 score 0.4829193002703341\n"
     ]
    }
   ],
   "source": [
    "print(\"Results on test set\")\n",
    "print(\"Accuracy\" , test_accu)\n",
    "print(\"F1 score\" , test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFgimLOaUl1e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "six_train.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
